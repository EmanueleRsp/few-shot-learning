{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Generalized Few-Shot Learning (GFSL)**\n",
        "\n",
        "This demo implements **Dynamic Few-Shot Learning without Forgetting** (DFSLwF) on the **CIFAR-100** dataset under the *generalized setting*, where both base and novel classes are present at test time. The notebook reproduces the two-stage training pipeline (supervised base training followed by episodic meta-training with a generator) and allows readers to evaluate base, novel, and harmonic accuracies in the **GFSL scenario**."
      ],
      "metadata": {
        "id": "tFoEk1MspnUb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "PgPkCPJxpl63"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Background**"
      ],
      "metadata": {
        "id": "CFGadMzopx5K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.1 Generalized Few-Shot Learning (GFSL)**\n",
        "\n",
        "In GFSL the evaluation setup changes: during testing, queries can belong to either  \n",
        "- **base classes** (those already seen during training), or  \n",
        "- **novel classes** (new ones introduced only at test time).  \n",
        "\n",
        "The learner must recognize queries across this **joint label space**, handling both familiar and unseen categories simultaneously. This setting is more realistic than classical FSL, where queries always belong to novel classes only.\n",
        "\n",
        "> **Example (GFSL 3-way 2-shot):** suppose the model was trained on 64 base classes. At test time, an episode may include queries from both these base classes and 3 novel ones, each with only 2 support examples. The learner must correctly classify across all base + novel classes.\n",
        "\n",
        "A challenge arises: the model tends to be **biased toward base classes**, since they are represented by many more examples during training.  \n",
        "Approaches like **Dynamic Few-Shot Learning without Forgetting (DFSLwF)** mitigate this issue by combining a base classifier (trained on abundant data) with a novel classifier (trained from few supports), and balancing their predictions at inference time.\n",
        "\n",
        "*(Evaluation tip: in GFSL, report separate accuracy on base and novel classes, plus the **harmonic mean (H-mean)** to capture overall balance.)*\n",
        "\n",
        "> **Practical scenario:** GFSL is valuable in real-world systems (e.g., an image recognition app) where the model must keep performing well on frequent categories like “dogs” or “cars” while also learning to recognize new, rare categories from just a handful of examples.\n"
      ],
      "metadata": {
        "id": "tiLuW00wp55a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.2 Dynamic Few-Shot Learning without Forgetting**\n",
        "\n",
        "Let $F_\\theta(\\cdot)$ be a ConvNet feature extractor.  \n",
        "A classifier is built using a set of **weight vectors** $W = \\{ w_k \\}$, one per class, and computes scores via a **cosine similarity**:\n",
        "\n",
        "$$\n",
        "s_k(x) \\;=\\; \\tau \\cdot \\cos\\!\\big( F_\\theta(x), w_k \\big),\n",
        "$$\n",
        "\n",
        "where both features and weights are $\\ell_2$-normalized, and $\\tau$ is a learnable scale.  \n",
        "This design ensures that base and novel categories are treated in a **unified space**.\n",
        "\n",
        "To incorporate novel classes at test time, DFSLwF introduces a **few-shot weight generator** $G(\\cdot)$:\n",
        "- Input: a small support set of feature vectors $Z' = \\{z'_i\\}$ from a novel class, plus the set of base weights $W_\\text{base}$,  \n",
        "- Output: a novel classification weight $w'$ for that class.\n",
        "\n",
        "The generator combines two mechanisms:\n",
        "1. **Feature averaging:**  \n",
        "   $w'_\\text{avg} = \\tfrac{1}{N'} \\sum_i z'_i$, scaled by learnable parameters.  \n",
        "2. **Attention over base weights:**  \n",
        "   Composes $w'_\\text{att}$ as a similarity-weighted sum of $W_\\text{base}$, exploiting prior knowledge about the visual world.  \n",
        "\n",
        "The final novel weight is a linear combination:  \n",
        "$$\n",
        "w' = \\phi_\\text{avg} \\odot w'_\\text{avg} \\;+\\; \\phi_\\text{att} \\odot w'_\\text{att}.\n",
        "$$\n",
        "\n",
        "At inference, the classifier uses  \n",
        "$$\n",
        "W^* = W_\\text{base} \\cup W_\\text{novel},\n",
        "$$  \n",
        "thus predicting across **both base and novel classes** without retraining.\n",
        "\n",
        "**Training procedure (two stages):**\n",
        "1. **Stage 1:** Train feature extractor + base classifier on abundant base data.  \n",
        "2. **Stage 2:** Train the weight generator using “fake” novel tasks sampled from base categories (episodic style).  \n",
        "\n",
        "**Notes (implementation):**\n",
        "- Removing the final ReLU in $F_\\theta$ helps cosine similarity classification.  \n",
        "- The $\\ell_2$-normalization enforces compact clusters, improving generalization to novel classes.  \n",
        "- Evaluation reports accuracy on **Base**, **Novel**, and the **harmonic mean (H-mean)**.  \n",
        "\n",
        "> **Why it matters:** DFSLwF directly addresses the **GFSL setting**: real systems must keep high performance on frequent base categories (e.g., “dogs”, “cars”) while adapting dynamically to rare, unseen ones (e.g., “drone types”) from few examples, without retraining or forgetting.\n"
      ],
      "metadata": {
        "id": "ZJGmdC0np5IB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.3 CIFAR-100 dataset**\n",
        "We also use [CIFAR-100](https://www.cs.toronto.edu/~kriz/cifar.html), a widely adopted benchmark for image classification.  \n",
        "It consists of **100 classes** (e.g., animals, vehicles, household objects), each containing **600 color images** of size $32 \\times 32$.  \n",
        "For every class, there are **500 training images** and **100 test images**.\n",
        "\n",
        "CIFAR-100 is more challenging than Omniglot or MNIST-like datasets, since it involves **natural RGB images** with high intra-class variability and smaller image resolution.\n",
        "\n",
        "It's included in the `torchvision` package, making it straightforward to download and preprocess for few-shot or generalized few-shot experiments.\n"
      ],
      "metadata": {
        "id": "5CzeVUAMqNiN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "AXRqQlJspyNl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Practice**"
      ],
      "metadata": {
        "id": "UAwYkSFHoebf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "import math\n",
        "import random\n",
        "import types\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "import copy\n",
        "from functools import partial\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import ConcatDataset, DataLoader, Subset\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import CIFAR100\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "0c0fLQwq5t_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seed:"
      ],
      "metadata": {
        "id": "nlrbjXRRoo-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "train_rng = np.random.default_rng(SEED + 1)\n",
        "test_rng = np.random.default_rng(SEED + 2)"
      ],
      "metadata": {
        "id": "h0QZmdPV52XF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Settings:"
      ],
      "metadata": {
        "id": "_6NNqLzFoxUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Few-shot episode configuration\n",
        "N_WAY = 5           # Number of classes per task\n",
        "K_SHOT = 5          # Support examples per class\n",
        "Q_NOVEL = 15        # Query examples per novel class\n",
        "Q_BASE_TOTAL = 75   # Query examples of base classes\n",
        "\n",
        "# CIFAR-100 split sizes\n",
        "N_BASE = 64         # Number of classes retained as base\n",
        "N_VALNOVEL = 16     # Number of classes retained as novel (for validation)\n",
        "N_TESTNOVEL = 20    # Number of classes retained as novel (for test)\n",
        "\n",
        "# Network params\n",
        "TAU_INIT = 10.0             # Temperature init\n",
        "BACKBONE = \"cifar_resnet\"   # Feature extractor network\n",
        "assert BACKBONE in [\"resnet18\", \"conv\", \"cifar_resnet\"], f\"Unknown backbone '{BACKBONE}'. Use 'conv', 'resnet18' or 'cifar_resnet'.\"\n",
        "\n",
        "# Stage 1\n",
        "STAGE1_EPOCHS = 120\n",
        "STAGE1_LR = 3e-3\n",
        "STAGE1_BS = 512\n",
        "STAGE1_WEIGHT_DECAY = 5e-4\n",
        "S1_VAL_FRAC   = 0.10   # Fraction of examples of base classes retained for validation\n",
        "S1_VAL_EVERY  = 2      # Validate every N epochs\n",
        "S1_PATIENCE   = 5      # Early-stopping after N validations without improvements\n",
        "S1_LOG_EVERY  = 50     # Log loss every N batches\n",
        "\n",
        "# Stage 2\n",
        "STAGE2_TASKS = 20_000         # Number of training episodes\n",
        "STAGE2_LR = 5e-4\n",
        "STAGE2_GRAD_CLIP  = 1.0\n",
        "S2_VAL_TASKS      = 1_000     # Number of validation episodes\n",
        "STAGE2_VAL_EVERY  = 500       # Validate every N episodes\n",
        "S2_PATIENCE       = 5         # Early-stopping after N validations without improvements\n",
        "S2_SELECT_METRIC  = \"hmean\"   # validation metric\n",
        "assert S2_SELECT_METRIC in [\"hmean\", \"base\", \"novel\"], f\"Unknown metric '{S2_SELECT_METRIC}'. Use 'hmean', 'base' or 'novel'.\"\n",
        "\n",
        "# Test\n",
        "TEST_TASKS = 1_000    # Number of test episodes"
      ],
      "metadata": {
        "id": "MvrrIQjKoxLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utility functions:"
      ],
      "metadata": {
        "id": "NOTdCwcdpGaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_cifar100_classes(seed: int, n_base=64, n_val=16, n_test=20):\n",
        "    \"\"\"Split CIFAR-100 class IDs into base/val-novel/test-novel sets.\n",
        "    \"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "    classes = np.arange(100); rng.shuffle(classes)\n",
        "    return classes[:n_base].tolist(), classes[n_base:n_base+n_val].tolist(), classes[n_base+n_val:n_base+n_val+n_test].tolist()\n",
        "\n",
        "\n",
        "def subset_by_classes(ds, keep):\n",
        "    \"\"\"Return a Subset containing only samples whose label is in `keep`.\n",
        "\n",
        "    Uses vectorized filtering over `ds.targets` to select the indices that\n",
        "    belong to the provided set of class IDs.\n",
        "    \"\"\"\n",
        "    t = np.array(ds.targets)\n",
        "    idx = np.nonzero(np.isin(t, keep))[0]\n",
        "    return Subset(ds, idx)\n",
        "\n",
        "\n",
        "def class_to_local_indices(subset):\n",
        "    \"\"\"Build a mapping class_id -> list of *local* indices within `subset`.\n",
        "\n",
        "    Iterates over the subset indices and groups them by their original class\n",
        "    ID (read from `subset.dataset.targets`). Useful for fast episodic sampling\n",
        "    (e.g., drawing K support and Q query images per class).\n",
        "\n",
        "    Example:\n",
        "    ```\n",
        "    {\n",
        "        0: [0, 5, 9, ...],\n",
        "        1: [1, 7, ...],\n",
        "        ...\n",
        "    }\n",
        "    ```\n",
        "    \"\"\"\n",
        "    t = np.array(subset.dataset.targets)\n",
        "    out = {}\n",
        "    for j, i in enumerate(subset.indices):\n",
        "        y = int(t[i])\n",
        "        (out.setdefault(y, [])).append(j)\n",
        "    return out\n",
        "\n",
        "\n",
        "def stratified_split_subset(subset: Subset, val_frac: float, seed: int):\n",
        "    \"\"\"\n",
        "    Split a Subset in (train_part, val_part),\n",
        "    maintaining proportions between each original CIFAR class.\n",
        "    \"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "    ds_targets = np.array(subset.dataset.targets)\n",
        "    # map: class_id -> local indexes list in Subset\n",
        "    cls2locals = {}\n",
        "    for j, i in enumerate(subset.indices):\n",
        "        y = int(ds_targets[i])\n",
        "        (cls2locals.setdefault(y, [])).append(j)\n",
        "\n",
        "    train_locals, val_locals = [], []\n",
        "    for y, locals_ in cls2locals.items():\n",
        "        locals_ = np.array(locals_, dtype=int)\n",
        "        n_val = max(1, int(round(len(locals_) * val_frac)))\n",
        "        rng.shuffle(locals_)\n",
        "        val_locals.append(locals_[:n_val])\n",
        "        train_locals.append(locals_[n_val:])\n",
        "\n",
        "    train_locals = np.concatenate(train_locals).tolist()\n",
        "    val_locals   = np.concatenate(val_locals).tolist()\n",
        "\n",
        "    train_indices = [subset.indices[i] for i in train_locals]\n",
        "    val_indices   = [subset.indices[i] for i in val_locals]\n",
        "\n",
        "    return Subset(subset.dataset, train_indices), Subset(subset.dataset, val_indices)"
      ],
      "metadata": {
        "id": "bRJokFSoC3Wo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def l2_normalize(x: torch.Tensor, dim: int = 1, eps: float = 1e-6) -> torch.Tensor:\n",
        "  \"\"\"L2-normalize a tensor along a given dimension.\n",
        "  \"\"\"\n",
        "  return x / (x.norm(p=2, dim=dim, keepdim=True).clamp_min(eps))"
      ],
      "metadata": {
        "id": "g6FYkq_npGJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_bn_eval(m: nn.Module):\n",
        "  \"\"\"Put BatchNorm2d layers in eval mode and freeze their parameters,\n",
        "  so it uses stored running statistics and stops updating them,\n",
        "  and it disables gradient updates for its affine parameters (gamma/beta).\n",
        "  \"\"\"\n",
        "  if isinstance(m, nn.BatchNorm2d):\n",
        "      m.eval()\n",
        "      for p in m.parameters():\n",
        "          p.requires_grad = False"
      ],
      "metadata": {
        "id": "nh0Z36WvpJ1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sliding_avg(xs: List[float], k: int = 20) -> float:\n",
        "  if not xs:\n",
        "      return 0.0\n",
        "  if len(xs) < k:\n",
        "      return float(sum(xs) / len(xs))\n",
        "  return float(sum(xs[-k:]) / k)"
      ],
      "metadata": {
        "id": "aXkLYzad5_UO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_ci95(xs: np.ndarray) -> Tuple[float, float]:\n",
        "    xs = np.asarray(xs, dtype=float)\n",
        "    n  = xs.size\n",
        "    if n < 2:\n",
        "        return float(xs.mean()), 0.0\n",
        "    std = xs.std(ddof=1)\n",
        "    stderr = std / np.sqrt(n)\n",
        "    z = 1.96\n",
        "    return float(xs.mean()), float(z * stderr)\n",
        "\n",
        "\n",
        "def gfsl_stats(\n",
        "    acc_per_ep_base: List[float],\n",
        "    acc_per_ep_novel: List[float],\n",
        ") -> Dict[str, Dict[str, float]]:\n",
        "\n",
        "    if len(acc_per_ep_base) != len(acc_per_ep_novel):\n",
        "        raise ValueError(\"base and novel must be of the same length\")\n",
        "    T = len(acc_per_ep_base)\n",
        "\n",
        "    base = np.asarray(acc_per_ep_base, dtype=float)\n",
        "    novel = np.asarray(acc_per_ep_novel, dtype=float)\n",
        "\n",
        "    denom = base + novel\n",
        "    h_per_ep = np.where(denom > 0, 2.0 * base * novel / denom, 0.0)\n",
        "\n",
        "    base_mean, base_ci  = mean_ci95(base)\n",
        "    novel_mean, novel_ci = mean_ci95(novel)\n",
        "    h_mean, h_ci = mean_ci95(h_per_ep)\n",
        "\n",
        "    return {\n",
        "        \"base\":  {\"mean\": base_mean,  \"conf\": base_ci},\n",
        "        \"novel\": {\"mean\": novel_mean, \"conf\": novel_ci},\n",
        "        \"hmean\": {\"mean\": h_mean,     \"conf\": h_ci},\n",
        "    }\n",
        "\n",
        "\n",
        "def print_stats(T: int, stats: Dict[str, Dict[str, float]], model: str = \"\"):\n",
        "  print(f\"[test] - {model} (95% CI on {T} tasks)\")\n",
        "  print(f\" - [Base]   acc={100*stats['base']['mean']:.2f}% ± {100*stats['base']['conf']:.2f}%\")\n",
        "  print(f\" - [Novel]  acc={100*stats['novel']['mean']:.2f}% ± {100*stats['novel']['conf']:.2f}%\")\n",
        "  print(f\" - [H-mean] acc={100*stats['hmean']['mean']:.2f}% ± {100*stats['hmean']['conf']:.2f}%\")"
      ],
      "metadata": {
        "id": "RWvm92IonBf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.1 Environment**"
      ],
      "metadata": {
        "id": "aRvCumaepV4w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.1.1 CIFAR100 dataset**\n",
        "\n",
        "We define **data transformations** separately for training and evaluation.  \n",
        "On **train**, we apply light stochastic augmentation suited to 32x32 images (random crop with padding and horizontal flip) to improve invariances without distorting small objects.  \n",
        "On **eval**, we keep a deterministic pipeline to ensure consistent measurement.\n",
        "\n",
        "> Augmentations reduce overfitting of the feature extractor in Stage-1. A stable eval pipeline is instead crucial when computing Base / Novel / H-mean in GFSL"
      ],
      "metadata": {
        "id": "NMpMP2wfpYWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if BACKBONE == \"conv\" or BACKBONE == \"cifar_resnet\":\n",
        "    IMAGE_SIZE = 32\n",
        "\n",
        "    train_tf = transforms.Compose([\n",
        "        transforms.RandomCrop(IMAGE_SIZE, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "    eval_tf = transforms.Compose([transforms.ToTensor(),])\n",
        "\n",
        "else:\n",
        "    IMNET_MEAN = [0.485, 0.456, 0.406]\n",
        "    IMNET_STD  = [0.229, 0.224, 0.225]\n",
        "    IM_RESIZE = 128\n",
        "    IM_CROP   = 112\n",
        "\n",
        "    train_tf = transforms.Compose([\n",
        "        transforms.Resize(IM_RESIZE),\n",
        "        transforms.RandomCrop(IM_CROP),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(IMNET_MEAN, IMNET_STD),\n",
        "    ])\n",
        "\n",
        "    eval_tf = transforms.Compose([\n",
        "        transforms.Resize(IM_RESIZE),\n",
        "        transforms.CenterCrop(IM_CROP),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(IMNET_MEAN, IMNET_STD),\n",
        "    ])"
      ],
      "metadata": {
        "id": "HwaG9qKI57p6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We instantiate the **GFSL** splits on CIFAR-100 as follows:\n",
        "- `ds_train` / `ds_test` load the standard CIFAR-100 **training** and **test** partitions with their respective transforms (`train_tf` randomized, `eval_tf` deterministic).\n",
        "- `split_cifar100_classes(SEED)` yields a **disjoint class split** into:\n",
        "  - **Base** classes (used for Stage-1 supervised training and as the base pool in GFSL episodes),\n",
        "  - **Val-Novel** classes (for model selection with GFSL episodes),\n",
        "  - **Test-Novel** classes (for final GFSL evaluation).\n",
        "\n",
        "All data live under `./data` and are fetched on demand with `download=True`.\n",
        "\n",
        "> *Note.* In GFSL, splits must be done **by class**, not by image, to avoid leakage. Label spaces are remapped locally for base vs. novel episodes so that evaluation is over the **joint label space** (Base ∪ Novel) while keeping indices compact inside each block.\n"
      ],
      "metadata": {
        "id": "AMHvYiUF1fKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train = CIFAR100(root=\"./data\", train=True,  transform=train_tf, download=True)\n",
        "ds_test  = CIFAR100(root=\"./data\", train=False, transform=eval_tf,  download=True)\n",
        "\n",
        "base, valn, testn = split_cifar100_classes(SEED)"
      ],
      "metadata": {
        "id": "QcTRsE73tYyU",
        "outputId": "e2ce2902-7a11-458c-cff1-91e55399beeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169M/169M [00:13<00:00, 12.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now **separate** the base training set into a train and validation split.  \n",
        "This allows us to monitor Stage-1 supervised training on base classes without leaking novel information.  \n",
        "We also prepare a distinct set of **val-novel classes** (from the train partition) to be used later for episodic validation in GFSL."
      ],
      "metadata": {
        "id": "k-d5W2u22YT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stage 1: Train + validation (base) / Stage 2: Train (base and pseudo-novel) + validation (base) - from train\n",
        "train_base_full = subset_by_classes(ds_train, base)\n",
        "train_base_tr, train_base_val = stratified_split_subset(train_base_full, S1_VAL_FRAC, SEED)\n",
        "\n",
        "# Stage 2: Validation (Novel) - from train\n",
        "train_valnovel = subset_by_classes(ds_train, valn)\n",
        "\n",
        "# Test (base + novel) - from test\n",
        "test_base  = subset_by_classes(ds_test,  base)\n",
        "test_novel = subset_by_classes(ds_test,  testn)"
      ],
      "metadata": {
        "id": "Zxqc9nIwBUTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we create the **label maps** for each split:  \n",
        "- local indices for base-train and base-val (Stage-1),  \n",
        "- mappings for val-novel classes (Stage-2 validation),  \n",
        "- and indices for base and novel classes in the final test set.  \n",
        "\n",
        "These compact class-to-indices maps are required for episodic samplers and joint logits during GFSL evaluation."
      ],
      "metadata": {
        "id": "FjpOdCMS2kPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stage-1 (supervised)\n",
        "cti_train_base_tr  = class_to_local_indices(train_base_tr)\n",
        "cti_train_base_val = class_to_local_indices(train_base_val)\n",
        "\n",
        "# Stage-2 Validation (episodic GFSL) - from train\n",
        "cti_val_base   = cti_train_base_val\n",
        "cti_val_novel  = class_to_local_indices(train_valnovel)\n",
        "\n",
        "# For test (episodic GFSL)\n",
        "cti_test_base  = class_to_local_indices(test_base)\n",
        "cti_test_novel = class_to_local_indices(test_novel)"
      ],
      "metadata": {
        "id": "TTGwCpCPBRPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.1.1.1 DataLoader: Stage 1**"
      ],
      "metadata": {
        "id": "m0uFfFH8tbjP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stage-1 trains the backbone + base classifier with sufficient base data, so we construct a classic **supervised loader** over **base classes only**:"
      ],
      "metadata": {
        "id": "ahogH9-e4GFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Stage1TrainDS(torch.utils.data.Dataset):\n",
        "    def __init__(self, subset: Subset, orig_targets: List[int], order_map: Dict[int, int]):\n",
        "        self.subset = subset\n",
        "        self.local_labels = [order_map[int(orig_targets[i])] for i in subset.indices]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.subset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x, _ = self.subset[idx]\n",
        "        return x, self.local_labels[idx]\n",
        "\n",
        "\n",
        "base_order = sorted(base)\n",
        "order_map  = {cid: i for i, cid in enumerate(base_order)}\n",
        "\n",
        "stage1_train_ds = Stage1TrainDS(train_base_tr,  ds_train.targets, order_map)  # train\n",
        "stage1_val_ds   = Stage1TrainDS(train_base_val, ds_train.targets, order_map)  # val (disjoined)"
      ],
      "metadata": {
        "id": "bIui-IjnGOfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We instantiate them:"
      ],
      "metadata": {
        "id": "SKMzCEqO40Cm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader_s1 = DataLoader(\n",
        "    stage1_train_ds, batch_size=STAGE1_BS, shuffle=True,\n",
        "    num_workers=2, pin_memory=True\n",
        ")\n",
        "\n",
        "val_loader_s1   = DataLoader(\n",
        "    stage1_val_ds, batch_size=STAGE1_BS*2, shuffle=False,\n",
        "    num_workers=2, pin_memory=True\n",
        ")"
      ],
      "metadata": {
        "id": "7UGqx2oStiVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.1.1.2 DataLoader: Stage 2 Train**"
      ],
      "metadata": {
        "id": "yGENDGSFtivp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the stage-2 training (but also for the validation and test phases), we need to evaluate the on **few-shot tasks**.\n",
        "A standard PyTorch `DataLoader` builds mini-batches of images without\n",
        "considering whether they belong to a support or query set.\n",
        "\n",
        "However, in a GFSL setting, the dataloader works differently from the classical FSL one, since we need episodes that combine **few-shot novel supports** with **base queries**.\n",
        "\n",
        "To achieve this, we use a **custom task sampler** and a **custom collate function**."
      ],
      "metadata": {
        "id": "-gmGPd3E8ZTM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Collate function**\n",
        "\n",
        "It splits the batch into:\n",
        "  1. `support_novel` images (size `n_way * k_shot`)  \n",
        "  2. `query_images` = `[novel queries | base queries]`  \n",
        "  3. `true_novel_ids` (original CIFAR-100 ids for the sampled novel classes)  \n",
        "  4. `base_query_labels_cifar` (original CIFAR-100 ids for base queries)"
      ],
      "metadata": {
        "id": "MLgR1QJy-VQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stage2_collate(batch, n_way: int, k_shot: int, q_novel: int, q_base_total: int):\n",
        "    imgs, labs = list(zip(*batch))\n",
        "    images = torch.stack(imgs)\n",
        "    labels = torch.tensor([int(y) for y in labs])\n",
        "\n",
        "    per_novel = k_shot + q_novel\n",
        "    total_novel = n_way * per_novel\n",
        "\n",
        "    novel_block = images[:total_novel].view(n_way, per_novel, *images.shape[1:])\n",
        "    novel_labels_block = labels[:total_novel].view(n_way, per_novel)\n",
        "\n",
        "    support_novel = novel_block[:, :k_shot].reshape(-1, *images.shape[1:])\n",
        "    query_novel = novel_block[:, k_shot:].reshape(-1, *images.shape[1:])\n",
        "    query_base = images[total_novel:]\n",
        "\n",
        "    query_images = torch.cat([query_novel, query_base], dim=0)\n",
        "\n",
        "    true_novel_ids = [int(novel_labels_block[i, 0].item()) for i in range(n_way)]\n",
        "    base_query_labels_cifar = labels[total_novel:]  # original CIFAR ids\n",
        "    return support_novel, query_images, true_novel_ids, base_query_labels_cifar\n",
        "\n",
        "\n",
        "stage2_collate_fn = partial(\n",
        "    stage2_collate,\n",
        "    n_way=N_WAY, k_shot=K_SHOT, q_novel=Q_NOVEL, q_base_total=Q_BASE_TOTAL,\n",
        ")"
      ],
      "metadata": {
        "id": "VKDRe5296RFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Batch sampler**\n",
        "\n",
        "Samples `n_way` pseudo-novel classes from the base pool, drawing `k_shot + q_novel` examples per class. It then adds `q_base_total` queries from the remaining base classes.\n"
      ],
      "metadata": {
        "id": "RpUErJzs-Mjl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GFSLTrainEpisodicBatchSampler:\n",
        "    \"\"\"\n",
        "    Stage-2: N_WAY pseudo-novel (from BASE train) with K+Qn each + Qb base queries from BASE (any class).\n",
        "    Returns indices over the Subset(train_base).\n",
        "    \"\"\"\n",
        "    def __init__(self, class_to_indices: Dict[int, List[int]], n_tasks: int, rng: np.random.Generator,\n",
        "                 n_way: int = N_WAY, k_shot: int = K_SHOT, q_novel: int = Q_NOVEL, q_base_total: int = Q_BASE_TOTAL):\n",
        "        self.cti = class_to_indices\n",
        "        self.all_classes = list(class_to_indices.keys())\n",
        "        self.n_tasks = n_tasks\n",
        "        self.rng = rng\n",
        "        self.n_way = n_way\n",
        "        self.k_shot = k_shot\n",
        "        self.q_novel = q_novel\n",
        "        self.q_base_total = q_base_total\n",
        "\n",
        "    def __len__(self): return self.n_tasks\n",
        "\n",
        "    def __iter__(self):\n",
        "        for _ in range(self.n_tasks):\n",
        "\n",
        "            novel = self.rng.choice(self.all_classes, size=self.n_way, replace=False)\n",
        "\n",
        "            batch = []\n",
        "            for c in novel:\n",
        "                pool = self.cti[c]\n",
        "                need = self.k_shot + self.q_novel\n",
        "                if len(pool) < need:\n",
        "                    raise ValueError(f\"Class {c} has {len(pool)} < {need}\")\n",
        "                idx = self.rng.choice(pool, size=need, replace=False)\n",
        "                batch.append(idx)\n",
        "\n",
        "            novel_classes = set(novel.tolist())\n",
        "            base_pool_classes = [c for c in self.all_classes if c not in novel_classes]\n",
        "\n",
        "            used = set(np.concatenate(batch).tolist())\n",
        "\n",
        "            base_q = []\n",
        "            while len(base_q) < self.q_base_total:\n",
        "                c = int(self.rng.choice(base_pool_classes))\n",
        "                cand = int(self.rng.choice(self.cti[c]))\n",
        "                if cand not in used:\n",
        "                    base_q.append(cand)\n",
        "                    used.add(cand)\n",
        "\n",
        "            batch.append(np.array(base_q, dtype=int))\n",
        "            yield np.concatenate(batch)\n",
        "\n",
        "\n",
        "stage2_train_batch_sampler = GFSLTrainEpisodicBatchSampler(\n",
        "    cti_train_base_tr, n_tasks=STAGE2_TASKS, rng=train_rng,\n",
        "    n_way=N_WAY, k_shot=K_SHOT, q_novel=Q_NOVEL, q_base_total=Q_BASE_TOTAL\n",
        ")"
      ],
      "metadata": {
        "id": "jWdAwrxL6KH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now create our Dataset..."
      ],
      "metadata": {
        "id": "1h_2qLA3-bY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Stage2TrainDS(torch.utils.data.Dataset):\n",
        "    def __init__(self, subset: Subset):\n",
        "        self.subset = subset\n",
        "    def __len__(self):\n",
        "      return len(self.subset)\n",
        "    def __getitem__(self, idx):\n",
        "      return self.subset[idx]\n",
        "\n",
        "\n",
        "stage2_train_ds = Stage2TrainDS(train_base_tr)"
      ],
      "metadata": {
        "id": "zyl7POdxWpoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "... and build the DataLoader:"
      ],
      "metadata": {
        "id": "5ViakuhC-f_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader_s2 = DataLoader(\n",
        "    stage2_train_ds, batch_sampler=stage2_train_batch_sampler,\n",
        "    collate_fn=stage2_collate_fn, num_workers=2, pin_memory=True\n",
        ")"
      ],
      "metadata": {
        "id": "0-sHBaXruHqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.1.1.3 DataLoader: Stage 2 Validation and Test**"
      ],
      "metadata": {
        "id": "mxGopBG5u_6A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For validation and test we need a **different sampler + collate** than in training, because episodes must follow the **GFSL evaluation protocol**:  \n",
        "- sample supports and queries only from the **novel split**,  \n",
        "- add a fixed number of queries from the **base split**,  \n",
        "- keep the layout `[novel block | base block]` so evaluation can compute accuracy on Base, Novel, and H-mean.  \n",
        "\n",
        "The custom sampler/collate ensure this structure and prevent any leakage between base and novel classes.\n"
      ],
      "metadata": {
        "id": "PPhKuotIACu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_collate(batch, n_way: int, k_shot: int, q_novel: int, q_base_total: int):\n",
        "    \"\"\"Reconstruct support/query tensors for a GFSL test episode.\n",
        "\n",
        "    Input `batch` is a list of (image, label) from `test_concat` where the first\n",
        "    N_WAY*(K_SHOT+Q_NOVEL) items belong to the novel subset and the remaining Q_BASE_TOTAL\n",
        "    items belong to the base subset.\n",
        "    \"\"\"\n",
        "    imgs, labs = list(zip(*batch))\n",
        "    images = torch.stack(imgs)\n",
        "    labels = torch.tensor([int(y) for y in labs])\n",
        "\n",
        "    per_novel = k_shot + q_novel\n",
        "    total_novel = n_way * per_novel\n",
        "\n",
        "    # reshape novel block into (N, K+Qn, C, H, W) and (N, K+Qn) for labels\n",
        "    novel_block = images[:total_novel].view(n_way, per_novel, *images.shape[1:])\n",
        "    novel_labels_block = labels[:total_novel].view(n_way, per_novel)\n",
        "\n",
        "    # split into support (first K) and query (last Qn)\n",
        "    support_novel = novel_block[:, :k_shot].reshape(-1, *images.shape[1:])\n",
        "    query_novel   = novel_block[:, k_shot:].reshape(-1, *images.shape[1:])\n",
        "    query_base    = images[total_novel:]  # remaining Qb from base subset\n",
        "\n",
        "    # concatenate all queries [novel | base]\n",
        "    query_images = torch.cat([query_novel, query_base], dim=0)\n",
        "\n",
        "    # collect true novel CIFAR IDs (one per class) and per-query GT labels\n",
        "    true_novel_ids = [int(novel_labels_block[i, 0].item()) for i in range(n_way)]\n",
        "    gt_novel = novel_labels_block[:, k_shot:].reshape(-1)\n",
        "    gt_base  = labels[total_novel:]\n",
        "\n",
        "    return support_novel, query_images, true_novel_ids, gt_novel, gt_base\n",
        "\n",
        "\n",
        "eval_collate_fn = partial(\n",
        "    eval_collate,\n",
        "    n_way=N_WAY, k_shot=K_SHOT, q_novel=Q_NOVEL, q_base_total=Q_BASE_TOTAL,\n",
        ")"
      ],
      "metadata": {
        "id": "PmIR_s8bVaDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GFSLEvalEpisodeSampler:\n",
        "    \"\"\"Batch sampler for GFSL test episodes over a single ConcatDataset.\n",
        "\n",
        "    Each yielded batch is a 1D numpy array of indices into `test_concat`\n",
        "    laid out as:\n",
        "        [ N_WAY*(K_SHOT+Q_NOVEL) indices from novel part | Q_BASE_TOTAL indices from base part ]\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_cti: Dict[int, List[int]], novel_cti: Dict[int, List[int]], offset_base: int,\n",
        "                 n_tasks: int, rng: np.random.Generator,\n",
        "                 n_way: int = N_WAY, k_shot: int = K_SHOT, q_novel: int = Q_NOVEL, q_base_total: int = Q_BASE_TOTAL):\n",
        "        self.base_cti = base_cti\n",
        "        self.novel_cti = novel_cti\n",
        "        self.offset_base = offset_base\n",
        "\n",
        "        self.base_classes  = list(base_cti.keys())\n",
        "        self.novel_classes = list(novel_cti.keys())\n",
        "\n",
        "        self.n_tasks = n_tasks\n",
        "        self.rng = rng\n",
        "        self.n_way = n_way\n",
        "        self.k_shot = k_shot\n",
        "        self.q_novel = q_novel\n",
        "        self.q_base_total = q_base_total\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_tasks\n",
        "\n",
        "    def __iter__(self):\n",
        "        for _ in range(self.n_tasks):\n",
        "            # ---- NOVEL BLOCK (test_novel) ----\n",
        "            chosen_novel = self.rng.choice(self.novel_classes, size=self.n_way, replace=False)\n",
        "            per_novel = self.k_shot + self.q_novel\n",
        "\n",
        "            novel_chunks = []\n",
        "            for c in chosen_novel:\n",
        "                pool = self.novel_cti[c]  # local indices within test_novel\n",
        "                if len(pool) < per_novel:\n",
        "                    raise ValueError(f\"Novel class {c} has {len(pool)} < {per_novel}\")\n",
        "                idx = self.rng.choice(pool, size=per_novel, replace=False)\n",
        "                novel_chunks.append(idx)\n",
        "\n",
        "            novel_block = np.concatenate(novel_chunks).astype(int)  # still in \"novel\" namespace (no offset)\n",
        "\n",
        "            # ---- BASE BLOCK (test_base) - NO DUPLICATES, NO REPLACEMENT ----\n",
        "            # Build a single pool of local indices from all base classes\n",
        "            base_pool = np.concatenate([self.base_cti[c] for c in self.base_classes]) if self.base_classes else np.array([], dtype=int)\n",
        "            if len(base_pool) < self.q_base_total:\n",
        "                raise ValueError(f\"Not enough base candidates: have {len(base_pool)} < {self.q_base_total}\")\n",
        "\n",
        "            # Sample Qb distinct local indices, then shift by offset to address ConcatDataset second component\n",
        "            base_q_local = self.rng.choice(base_pool, size=self.q_base_total, replace=False)\n",
        "            base_block   = (base_q_local + self.offset_base).astype(int)\n",
        "\n",
        "            # ---- FINAL EPISODE ----\n",
        "            full_episode = np.concatenate([novel_block, base_block])\n",
        "            yield full_episode"
      ],
      "metadata": {
        "id": "V1IuPKZRVVzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation (Stage-2) dataLoader:"
      ],
      "metadata": {
        "id": "t6ylrgepIMi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampler_val_s2 = GFSLEvalEpisodeSampler(\n",
        "    cti_val_base, cti_val_novel, len(train_valnovel), n_tasks=S2_VAL_TASKS, rng=test_rng,\n",
        "    n_way=N_WAY, k_shot=K_SHOT, q_novel=Q_NOVEL, q_base_total=Q_BASE_TOTAL\n",
        ")"
      ],
      "metadata": {
        "id": "jWw60OHxI8gv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a single test dataset by concatenating the two subsets.\n",
        "# Order matters: novel part first, base part second.\n",
        "val_concat_s2 = ConcatDataset([train_valnovel, train_base_val])"
      ],
      "metadata": {
        "id": "iveYcIVtIeoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loader_s2 = DataLoader(\n",
        "    val_concat_s2, batch_sampler=sampler_val_s2, collate_fn=eval_collate_fn,\n",
        "    num_workers=2, pin_memory=True\n",
        ")"
      ],
      "metadata": {
        "id": "2aeVNuJ3IORR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test DataLoader:"
      ],
      "metadata": {
        "id": "tCYjO5btILKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampler_test = GFSLEvalEpisodeSampler(\n",
        "    cti_test_base, cti_test_novel, len(test_novel), n_tasks=TEST_TASKS, rng=test_rng,\n",
        "    n_way=N_WAY, k_shot=K_SHOT, q_novel=Q_NOVEL, q_base_total=Q_BASE_TOTAL\n",
        ")"
      ],
      "metadata": {
        "id": "_5qt7i5sIppg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a single test dataset by concatenating the two subsets.\n",
        "# Order matters: novel part first, base part second.\n",
        "test_concat = ConcatDataset([test_novel, test_base])"
      ],
      "metadata": {
        "id": "R0ZCnKHVfmo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = DataLoader(\n",
        "    test_concat, batch_sampler=sampler_test, collate_fn=eval_collate_fn,\n",
        "    num_workers=2, pin_memory=True\n",
        ")"
      ],
      "metadata": {
        "id": "l5nkZ9_uvDbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.1.2 DFSLwF module**\n",
        "\n",
        "We define our network as a torch module composed by three main modules: a **feature extractor**, a **cosine classifier** and a **Few-shot weight generator**."
      ],
      "metadata": {
        "id": "Q4Zt-0FOrjzs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.1.2.1 Feature extractor**\n",
        "\n",
        "It's made up by a convolutional backbone that maps each input image to a feature vector.\n",
        "\n",
        "In our code we can choose between 3 different backbones:\n",
        "\n",
        "- **A small Residual Network**:"
      ],
      "metadata": {
        "id": "8HUI14SjArDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlockCIFAR(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, stride=1, remove_last_relu=False):\n",
        "        super().__init__()\n",
        "        self.remove_last_relu = remove_last_relu\n",
        "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1   = nn.BatchNorm2d(out_ch)\n",
        "        self.relu  = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, stride=1, padding=1, bias=False)\n",
        "        self.bn2   = nn.BatchNorm2d(out_ch)\n",
        "        self.down  = None\n",
        "        if stride != 1 or in_ch != out_ch:\n",
        "            self.down = nn.Sequential(\n",
        "                nn.Conv2d(in_ch, out_ch, 1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_ch),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        out = self.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        if self.down is not None:\n",
        "            identity = self.down(x)\n",
        "        out = out + identity\n",
        "        if not self.remove_last_relu:\n",
        "            out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class CIFARResNetSmall(nn.Module):\n",
        "    \"\"\"\n",
        "    ResNet 'cifar-like' per 32x32:\n",
        "      stem 3x3 s1 -> [64]x2 -> [128]x2 (s2) -> [256]x2 (s2) -> GAP -> 256-D\n",
        "    \"\"\"\n",
        "    def __init__(self, remove_last_relu: bool = True):\n",
        "        super().__init__()\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.layer1 = nn.Sequential(\n",
        "            BasicBlockCIFAR(64, 64, 1),\n",
        "            BasicBlockCIFAR(64, 64, 1),\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            BasicBlockCIFAR(64, 128, 2),   # downsample 32->16\n",
        "            BasicBlockCIFAR(128, 128, 1),\n",
        "        )\n",
        "        self.layer3 = nn.Sequential(\n",
        "            BasicBlockCIFAR(128, 256, 2),  # downsample 16->8\n",
        "            BasicBlockCIFAR(256, 256, 1, remove_last_relu=remove_last_relu),\n",
        "        )\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
        "        self.out_dim = 256\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        x = self.layer1(x); x = self.layer2(x); x = self.layer3(x)\n",
        "        x = self.gap(x).squeeze(-1).squeeze(-1)  # (B,256)\n",
        "        return x"
      ],
      "metadata": {
        "id": "hH7c_e8POaS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- A simple **Convolutional Neural Network**:"
      ],
      "metadata": {
        "id": "2YQTCrjUok_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    \"\"\"Conv3x3 -> BN -> ReLU -> (optional MaxPool2d).\"\"\"\n",
        "    def __init__(self, in_ch, out_ch, pool: bool):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, bias=False)\n",
        "        self.bn   = nn.BatchNorm2d(out_ch)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.pool = nn.MaxPool2d(2) if pool else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x); x = self.bn(x); x = self.relu(x); x = self.pool(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "1eh6yJqnOcFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Or the already implemented **ResNet18**.\n",
        "\n",
        "The model we chose is then implemented in the `FeatureExtractor` module:\n",
        "\n"
      ],
      "metadata": {
        "id": "sDY94IqFosvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureExtractor(nn.Module):\n",
        "    \"\"\"Feature extractor with selectable backbone: 'conv' (light), 'cifar_resnet' or 'resnet18'.\n",
        "\n",
        "    Args:\n",
        "        backbone: 'conv', 'resnet18' or 'cifar_resnet'.\n",
        "        normalize_out: if True, L2-normalize the output features.\n",
        "        resnet_pretrained: if True (only for 'resnet18'), load ImageNet pretrained weights.\n",
        "        remove_last_relu: if True (only for 'resnet18'), remove the last post-add ReLU in the final BasicBlock\n",
        "                          (useful with cosine classifiers).\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        backbone: str = \"conv\",\n",
        "        normalize_out: bool = True,\n",
        "        resnet_pretrained: bool = True,\n",
        "        remove_last_relu: bool = True,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.normalize_out = normalize_out\n",
        "\n",
        "        if backbone.lower() == \"conv\":\n",
        "            self.fe = nn.Sequential(\n",
        "                ConvBlock(3,   64, pool=True),   # 32 -> 16\n",
        "                ConvBlock(64,  64, pool=True),   # 16 -> 8\n",
        "                ConvBlock(64,  64, pool=False),\n",
        "                ConvBlock(64,  64, pool=False),\n",
        "                nn.AdaptiveAvgPool2d(1),         # -> (B,64,1,1)\n",
        "            )\n",
        "            self._mode = \"conv\"\n",
        "            self.out_dim = 64\n",
        "\n",
        "        elif backbone.lower() == \"cifar_resnet\":\n",
        "            self.fe = CIFARResNetSmall(remove_last_relu=remove_last_relu)\n",
        "            self._mode = \"cifar_resnet\"; self.out_dim = 256\n",
        "\n",
        "        elif backbone.lower() == \"resnet18\":\n",
        "            weights = ResNet18_Weights.IMAGENET1K_V1 if resnet_pretrained else None\n",
        "            m = resnet18(weights=weights)\n",
        "            m.fc = nn.Identity()  # we want the 512-D penultimate features\n",
        "\n",
        "            if remove_last_relu:\n",
        "                # Patch only the final BasicBlock to skip the post-add ReLU\n",
        "                last_block = m.layer4[-1]\n",
        "\n",
        "                def forward_norelu(self_block, x):\n",
        "                    identity = x\n",
        "                    out = self_block.conv1(x); out = self_block.bn1(out); out = self_block.relu(out)\n",
        "                    out = self_block.conv2(out); out = self_block.bn2(out)\n",
        "                    if self_block.downsample is not None:\n",
        "                        identity = self_block.downsample(x)\n",
        "                    out = out + identity\n",
        "                    return out  # no final ReLU\n",
        "\n",
        "                last_block.forward = types.MethodType(forward_norelu, last_block)\n",
        "\n",
        "            self.fe = m\n",
        "            self._mode = \"resnet18\"\n",
        "            self.out_dim = 512\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown backbone '{backbone}'. Use 'conv', 'resnet18' or 'cifar_resnet'.\")\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        if self._mode == \"conv\":\n",
        "            z = self.fe(x).squeeze(-1).squeeze(-1)    # (B, 64)\n",
        "        else:  # resnet18\n",
        "            z = self.fe(x)                            # (B, 512)\n",
        "        return l2_normalize(z, dim=1) if self.normalize_out else z"
      ],
      "metadata": {
        "id": "BmbYd7mBr2y3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.1.2.2 Cosine Classifier**\n",
        "\n",
        "This is the component that transforms feature vectors into class scores.\n",
        "\n",
        "Instead of using a standard dot-product, it computes the **cosine similarity** between the feature vector $x$ extracted from the images and the weights vectors $W$ of each class:\n",
        "\n",
        "\n",
        "$$\n",
        "\\cos(\\mathbf{x}, \\mathbf{w}) = \\frac{\\mathbf{x}^{\\top}\\mathbf{w}}{\\|\\mathbf{x}\\|_2 \\, \\|\\mathbf{w}\\|_2}\n",
        "$$\n",
        "\n",
        "The result is scaled by a **learnable parameter $τ$**, which controls how sharp or flat the final softmax distribution is:\n",
        "\n",
        "$$\n",
        "y = τ * \\cos(\\mathbf{x}, \\mathbf{w})\n",
        "$$\n",
        "\n",
        "In fact, base class weights are learned gradually during Stage-1 training, while novel class weights are generated dynamically from just a few support examples.\n",
        "If we relied on raw magnitudes (as in a dot-product classifier), the two sets of weights would not be directly comparable.  \n",
        "**By using cosine similarity, the classifier ensures that both base and novel categories live in the same normalized space**, allowing fair competition between them when predicting the label of a query image.\n"
      ],
      "metadata": {
        "id": "7hDoYa5fA2zv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CosineClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    [DFSLwF] Cosine classifier with learnable temperature $τ$ (tau).\n",
        "    \"\"\"\n",
        "    def __init__(self, in_dim: int, n_classes: int, init_scale: float = TAU_INIT):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.empty(n_classes, in_dim))\n",
        "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
        "        self.tau = nn.Parameter(torch.tensor(float(init_scale)))\n",
        "\n",
        "    def forward(self, feats: torch.Tensor) -> torch.Tensor:\n",
        "        W = l2_normalize(self.weight, dim=1)\n",
        "        feats = l2_normalize(feats, dim=1)\n",
        "        logits = feats @ W.t()\n",
        "        return self.tau * logits"
      ],
      "metadata": {
        "id": "6DmrwTPYr3Xd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.1.2.3 Few-Shot Weight Generator**\n",
        "\n",
        "\n",
        "Given $N$ novel classes, each with $K$ support examples, the generator produces one\n",
        "classification weight $ \\mathbf{w}'_c \\in \\mathbb{R}^D $ per novel class $c$ by combining:\n",
        "1) a **prototype** from support features and\n",
        "2) an **attention-guided mixture** of base weights.\n",
        "\n",
        "All outputs are L2-normalized so they are comparable to cosine-classifier weights.\n",
        "\n",
        "**Inputs**\n",
        "- Support features $ Z \\in \\mathbb{R}^{N\\times K \\times D} $ (already L2-normalized).\n",
        "- Base weights $ W_b \\in \\mathbb{R}^{C_{\\text{base}}\\times D} $.\n",
        "- Learnable **keys** $ K_b \\in \\mathbb{R}^{C_{\\text{base}}\\times D} $ (one per base class).\n",
        "- Learnable parameters: $ \\Phi_q \\in \\mathbb{R}^{D\\times D} $ (query layer),\n",
        "  $ \\boldsymbol{\\phi}_{\\text{avg}}, \\boldsymbol{\\phi}_{\\text{att}} \\in \\mathbb{R}^D $ (diagonal re-weighting),\n",
        "  and **temperature** $ \\gamma \\in \\mathbb{R}_{>0} $ for the attention softmax.\n",
        "\n",
        "**Step 1 - Class prototype (feature averaging)**  \n",
        "For each novel class $c$:\n",
        "$$\n",
        "\\mathbf{w}^{\\text{avg}}_c\n",
        "=\\operatorname{norm}_2\\!\\Big(\\frac{1}{K}\\sum_{i=1}^{K} \\mathbf{z}_{c,i}\\Big)\n",
        "\\qquad\\in\\mathbb{R}^D.\n",
        "$$\n",
        "\n",
        "**Step 2 - Attention over base classes**  \n",
        "Compute **queries** from support features and attend to base **keys**:\n",
        "$$\n",
        "\\tilde{\\mathbf{z}}_{c,i}=\\operatorname{norm}_2(\\Phi_q\\,\\mathbf{z}_{c,i}),\\quad\n",
        "\\tilde{K}_b=\\operatorname{norm}_2(K_b),\\quad\n",
        "\\tilde{W}_b=\\operatorname{norm}_2(W_b).\n",
        "$$\n",
        "Cosine attention logits and normalized weights:\n",
        "$$\n",
        "a_{c,i,b}\n",
        "=\\operatorname{softmax}_b\\!\\big(\\gamma\\,\\tilde{\\mathbf{z}}_{c,i}^{\\top}\\tilde{\\mathbf{k}}_b\\big),\n",
        "$$\n",
        "(optionally masking some base classes before the softmax).\n",
        "Aggregate the attended base weights and average across shots:\n",
        "$$\n",
        "\\mathbf{w}^{\\text{att}}_{c}\n",
        "=\\frac{1}{K}\\sum_{i=1}^{K}\\sum_{b=1}^{C_{\\text{base}}} a_{c,i,b}\\,\\tilde{\\mathbf{w}}_{b}\n",
        "\\quad\\in\\mathbb{R}^D.\n",
        "$$\n",
        "\n",
        "**Step 3 - Combine & normalize**  \n",
        "Re-weight the two components **per-dimension** and combine (Hadamard product $ \\odot $):\n",
        "$$\n",
        "\\mathbf{w}'_{c}\n",
        "=\\operatorname{norm}_2\\!\\Big(\\boldsymbol{\\phi}_{\\text{avg}}\\odot \\mathbf{w}^{\\text{avg}}_{c}\n",
        "+\\boldsymbol{\\phi}_{\\text{att}}\\odot \\mathbf{w}^{\\text{att}}_{c}\\Big).\n",
        "$$\n",
        "\n",
        "**Notes**\n",
        "- With $K=1$ the prototype reduces to the single support vector.\n",
        "- The temperature $\\gamma$ controls the **sharpness** of attention: large $\\gamma$ to focus on few base classes; small $\\gamma$ for smoother mixing.\n",
        "- Dropout on $Z$ is applied **only during Stage-2 training** to regularize the generator.\n",
        "- The final normalization ensures $ \\mathbf{w}'_c $ lives in the same space as cosine-classifier weights."
      ],
      "metadata": {
        "id": "Z82kcDtbA8Aw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FewShotWeightGenerator(nn.Module):\n",
        "    \"\"\"\n",
        "    [DFSLwF] Few-shot classification weight generator (Avg + Attention).\n",
        "    \"\"\"\n",
        "    def __init__(self, dim: int, num_base: int, p_dropout: float = 0.5):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.num_base = num_base\n",
        "        self.phi_q = nn.Linear(dim, dim, bias=False)\n",
        "        nn.init.kaiming_uniform_(self.phi_q.weight, a=math.sqrt(5))\n",
        "        self.keys = nn.Parameter(l2_normalize(torch.randn(num_base, dim), dim=1))\n",
        "        self.phi_avg = nn.Parameter(torch.ones(dim))\n",
        "        self.phi_att = nn.Parameter(torch.ones(dim))\n",
        "        self.gamma = nn.Parameter(torch.tensor(10.0))  # attention temperature (like τ)\n",
        "        self.dropout = nn.Dropout(p=p_dropout)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        support_feats: torch.Tensor,          # (N*K, D), L2-normalized\n",
        "        base_weights: torch.Tensor,           # (C_base, D), not necessarily normalized\n",
        "        shots_per_class: int,\n",
        "        exclude_mask: Optional[torch.Tensor] = None  # (C_base,) bool; True = keep; False = exclude\n",
        "    ) -> torch.Tensor:\n",
        "        D = support_feats.size(1)\n",
        "        N = support_feats.size(0) // shots_per_class\n",
        "        z = support_feats.view(N, shots_per_class, D)\n",
        "        if self.training:\n",
        "            z = self.dropout(z)\n",
        "        # w_avg\n",
        "        w_avg = l2_normalize(z.mean(dim=1), dim=1)  # (N, D)\n",
        "        # attention over base weights\n",
        "        Wb = l2_normalize(base_weights, dim=1)      # (C_base, D)\n",
        "        Kb = l2_normalize(self.keys, dim=1)         # (C_base, D)\n",
        "        # queries\n",
        "        q = self.phi_q(z)                           # (N, K, D)\n",
        "        q = l2_normalize(q, dim=2)                 # normalize across D\n",
        "        # cosine(q, Kb) => (N, K, C_base)\n",
        "        att_logits = torch.einsum(\"nkd,bd->nkb\", q, Kb) * self.gamma\n",
        "        if exclude_mask is not None:\n",
        "            # set -inf on excluded classes before softmax\n",
        "            mask = exclude_mask.view(1, 1, -1)  # broadcast\n",
        "            att_logits = att_logits.masked_fill(~mask, float(\"-inf\"))\n",
        "        att = torch.softmax(att_logits, dim=2)      # (N, K, C_base)\n",
        "        # weighted sum of base weights -> (N, K, D), then average over K (shots)\n",
        "        w_att = torch.einsum(\"nkb,bd->nkd\", att, Wb).mean(dim=1)  # (N, D)\n",
        "        # combine\n",
        "        w = self.phi_avg * w_avg + self.phi_att * w_att            # Hadamard\n",
        "        w = l2_normalize(w, dim=1)  # (N, D)\n",
        "        return w"
      ],
      "metadata": {
        "id": "1SVW654R6Fmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.1.2.4 Final Network: DFSLwF module**\n",
        "\n",
        "At inference time, the **Feature Extractor (FE)** maps an image to a L2-normalized embedding.\n",
        "\n",
        "For few-shot episodes, the **Few-Shot Weight Generator** takes the support embeddings and the **base** class weights and produces **novel** class weights by combining:\n",
        "1. Feature averaging (prototypes),\n",
        "2. Attention over base classes.\n",
        "\n",
        "The result is L2-normalized so it’s comparable to base weights.\n",
        "\n",
        "The **Cosine Classifier** then scores a query embedding against (normalized) base weights, and, if provided, against the generated novel weights, scaling all logits by the learnable temperature. Final predictions use **Softmax** on these concatenated logits.\n"
      ],
      "metadata": {
        "id": "gbYrjeFfBE86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DFSLwF(nn.Module):\n",
        "    def __init__(self, fe: FeatureExtractor, clf_base: CosineClassifier, gen: FewShotWeightGenerator):\n",
        "        super().__init__()\n",
        "        self.fe = fe\n",
        "        self.clf_base = clf_base\n",
        "        self.gen = gen\n",
        "\n",
        "    def forward_logits(\n",
        "        self,\n",
        "        x: torch.Tensor,\n",
        "        novel_weights: torch.Tensor | None = None,\n",
        "        base_keep_mask: torch.Tensor | None = None,   # <--- NEW (optional)\n",
        "    ) -> torch.Tensor:\n",
        "        feats = self.fe(x)                                        # (B, D)\n",
        "        Wb = l2_normalize(self.clf_base.weight, dim=1)            # (C_base, D)\n",
        "        if base_keep_mask is not None:\n",
        "            Wb = Wb[base_keep_mask]                               # keep-only base\n",
        "        logits = self.clf_base.tau * (feats @ Wb.t())             # base logits\n",
        "\n",
        "        if novel_weights is not None and novel_weights.numel() > 0:\n",
        "            Wn = l2_normalize(novel_weights, dim=1)               # (C_novel, D)\n",
        "            logits_n = self.clf_base.tau * (feats @ Wn.t())\n",
        "            logits = torch.cat([logits, logits_n], dim=1)\n",
        "        return logits\n",
        "\n",
        "    def build_novel_weights(\n",
        "        self,\n",
        "        support_imgs: torch.Tensor,\n",
        "        k_shot: int,\n",
        "        exclude_mask: torch.Tensor | None = None,                 # <--- pass through\n",
        "    ) -> torch.Tensor:\n",
        "        supp = self.fe(support_imgs)                              # (N*K, D), L2-norm\n",
        "        Wb = self.clf_base.weight\n",
        "        return self.gen(supp, Wb, k_shot, exclude_mask=exclude_mask)"
      ],
      "metadata": {
        "id": "Sf1nyTmgsJmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can build our network following the initial settings:"
      ],
      "metadata": {
        "id": "mUnlmgXkBQKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if BACKBONE == \"conv\":\n",
        "    fe = FeatureExtractor(backbone=BACKBONE, normalize_out=True)\n",
        "elif BACKBONE == \"cifar_resnet\":\n",
        "    fe = FeatureExtractor(backbone=BACKBONE, normalize_out=True, remove_last_relu=True)\n",
        "elif BACKBONE == \"resnet18\":\n",
        "    fe = FeatureExtractor(backbone=BACKBONE, normalize_out=True, resnet_pretrained=True, remove_last_relu=True)\n",
        "else:\n",
        "    raise ValueError(f\"Unknown backbone '{BACKBONE}'. Use 'conv', 'resnet18' or 'cifar_resnet'.\")\n",
        "\n",
        "clf = CosineClassifier(in_dim=fe.out_dim, n_classes=len(base_order))\n",
        "gen = FewShotWeightGenerator(dim=fe.out_dim, num_base=len(base_order), p_dropout=0.5)\n",
        "\n",
        "model = DFSLwF(fe=fe, clf_base=clf, gen=gen).to(device)"
      ],
      "metadata": {
        "id": "zXx49_x5vS-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_model = copy.deepcopy(model)"
      ],
      "metadata": {
        "id": "V6-K32td3uTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.2 Training**\n",
        "\n",
        "The training is split into two distinct stages:\n",
        "\n",
        "1. **Base supervised training** which builds a discriminative embedding for the base classes;\n",
        "2. **Episodic training** that teaches the model to dynamically generate classification weights for unseen classes, while still preserving performance on the base ones *without forgetting*."
      ],
      "metadata": {
        "id": "pwqrdqc9DitQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.2.1 Stage 1: supervised base training**\n",
        "\n",
        "The first phase consists of training the **feature extractor (FE)** and the **cosine base classifier** on the base classes with standard cross-entropy.  \n",
        "\n",
        "The goal is to learn a strong embedding space where base weights are well aligned with their class features.\n",
        "\n",
        "> *Note:* BatchNorm layers remain learnable (not frozen), as in a standard supervised classifier."
      ],
      "metadata": {
        "id": "9rRpFEbisZky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def evaluate_stage1_base_top1(model: DFSLwF, loader: DataLoader, device) -> float:\n",
        "    model.fe.eval(); model.clf_base.eval()\n",
        "    correct, total = 0, 0\n",
        "    for xb, yb in loader:\n",
        "        xb = xb.to(device); yb = yb.to(device)\n",
        "        logits = model.clf_base(model.fe(xb))\n",
        "        pred = logits.argmax(dim=1)\n",
        "        correct += (pred == yb).sum().item()\n",
        "        total   += yb.numel()\n",
        "    return correct / max(1, total)"
      ],
      "metadata": {
        "id": "0LvUzNjVF-6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_stage1(model: DFSLwF, loader: DataLoader, device: torch.device,\n",
        "                 epochs: int = STAGE1_EPOCHS, lr: float = STAGE1_LR,\n",
        "                 weight_decay: float = STAGE1_WEIGHT_DECAY,\n",
        "                 val_loader: Optional[DataLoader] = None):\n",
        "\n",
        "    # [DFSLwF] Train feature extractor + base classifier (cosine)\n",
        "    model.fe.train(); model.clf_base.train(); model.gen.eval()\n",
        "\n",
        "    # Keep BN learnable here (paper trains a standard classifier in Stage-1)\n",
        "    params    = list(model.fe.parameters()) + list(model.clf_base.parameters())\n",
        "    opt       = torch.optim.Adam(params, lr=lr, weight_decay=weight_decay)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Params for validation\n",
        "    best_val = -1.0\n",
        "    patience = 0\n",
        "    best_state = None\n",
        "\n",
        "    with tqdm(range(epochs), desc=\"[Stage1] Supervised base training\") as epbar:\n",
        "        for ep in epbar:\n",
        "            model.fe.train(); model.clf_base.train()\n",
        "            batch_losses = []\n",
        "\n",
        "            for i, (xb, yb) in enumerate(loader):\n",
        "                xb = xb.to(device); yb = yb.to(device)\n",
        "                opt.zero_grad()\n",
        "                logits = model.clf_base(model.fe(xb))\n",
        "                loss   = criterion(logits, yb)\n",
        "                loss.backward()\n",
        "                opt.step()\n",
        "                batch_losses.append(float(loss.item()))\n",
        "\n",
        "                if (i + 1) % S1_LOG_EVERY == 0:\n",
        "                    epbar.set_postfix(loss=f\"{sliding_avg(batch_losses, S1_LOG_EVERY):.4f}\")\n",
        "\n",
        "            # ---- PERIODIC VALIDATION ----\n",
        "            if val_loader is not None and ((ep + 1) % S1_VAL_EVERY == 0):\n",
        "                val_acc = evaluate_stage1_base_top1(model, val_loader, device)\n",
        "                epbar.write(f\"\\t[stage1/val] epoch {ep+1:03d}: acc_base={100*val_acc:.2f}%\")\n",
        "\n",
        "                if val_acc > best_val + 1e-6:\n",
        "                    best_val   = val_acc\n",
        "                    patience   = 0\n",
        "                    best_state = {\n",
        "                        \"model\": copy.deepcopy(model.state_dict()),\n",
        "                        \"opt\":   copy.deepcopy(opt.state_dict()),\n",
        "                        \"epoch\": ep + 1,\n",
        "                        \"val\":   best_val,\n",
        "                    }\n",
        "                else:\n",
        "                    patience += 1\n",
        "                    if patience >= S1_PATIENCE:\n",
        "                        epbar.write(f\"[stage1] Early stopping (no improvement for {S1_PATIENCE} validations).\")\n",
        "                        break\n",
        "\n",
        "    # Restore best result\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state[\"model\"])"
      ],
      "metadata": {
        "id": "UKTZWOz4V6wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = copy.deepcopy(baseline_model)\n",
        "train_stage1(model, train_loader_s1, device=device, val_loader=val_loader_s1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boHxe6JoviaS",
        "outputId": "0b205434-7b62-4c1f-99cc-d0b3d5b57d18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage1] Supervised base training:   2%|▏         | 2/120 [00:37<37:06, 18.86s/it, loss=3.1845]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage1/val] epoch 002: acc_base=11.84%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage1] Supervised base training:   3%|▎         | 4/120 [01:15<36:26, 18.85s/it, loss=2.5496]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage1/val] epoch 004: acc_base=26.06%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage1] Supervised base training:   5%|▌         | 6/120 [01:52<35:36, 18.75s/it, loss=2.1277]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage1/val] epoch 006: acc_base=25.47%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage1] Supervised base training:   7%|▋         | 8/120 [02:29<34:55, 18.71s/it, loss=1.8668]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage1/val] epoch 008: acc_base=30.88%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage1] Supervised base training:   8%|▊         | 10/120 [03:06<34:20, 18.73s/it, loss=1.6590]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage1/val] epoch 010: acc_base=39.69%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage1] Supervised base training:  10%|█         | 12/120 [03:43<33:39, 18.70s/it, loss=1.5021]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage1/val] epoch 012: acc_base=38.91%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage1] Supervised base training:  12%|█▏        | 14/120 [04:21<33:01, 18.69s/it, loss=1.3505]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage1/val] epoch 014: acc_base=34.22%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage1] Supervised base training:  13%|█▎        | 16/120 [04:58<32:25, 18.71s/it, loss=1.2418]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage1/val] epoch 016: acc_base=50.56%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage1] Supervised base training:  15%|█▌        | 18/120 [05:35<31:49, 18.72s/it, loss=1.1456]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage1/val] epoch 018: acc_base=49.12%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage1] Supervised base training:  17%|█▋        | 20/120 [06:12<31:14, 18.74s/it, loss=1.0685]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage1/val] epoch 020: acc_base=53.81%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage1] Supervised base training:  18%|█▊        | 22/120 [06:50<30:41, 18.79s/it, loss=0.9970]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage1/val] epoch 022: acc_base=55.84%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage1] Supervised base training:  20%|██        | 24/120 [07:27<30:03, 18.79s/it, loss=0.9345]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage1/val] epoch 024: acc_base=48.62%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage1] Supervised base training:  22%|██▏       | 26/120 [08:05<29:27, 18.80s/it, loss=0.8893]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage1/val] epoch 026: acc_base=58.13%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage1] Supervised base training:  23%|██▎       | 28/120 [08:42<28:55, 18.86s/it, loss=0.8559]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage1/val] epoch 028: acc_base=59.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage1] Supervised base training:  25%|██▌       | 30/120 [09:20<28:16, 18.85s/it, loss=0.8178]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage1/val] epoch 030: acc_base=57.12%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage1] Supervised base training:  27%|██▋       | 32/120 [09:57<27:37, 18.83s/it, loss=0.7743]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage1/val] epoch 032: acc_base=62.44%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage1] Supervised base training:  28%|██▊       | 34/120 [10:34<27:00, 18.85s/it, loss=0.7587]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage1/val] epoch 034: acc_base=60.31%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage1] Supervised base training:  30%|███       | 36/120 [11:12<26:21, 18.83s/it, loss=0.7165]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage1/val] epoch 036: acc_base=58.91%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage1] Supervised base training:  32%|███▏      | 38/120 [11:49<25:44, 18.83s/it, loss=0.7054]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage1/val] epoch 038: acc_base=60.62%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage1] Supervised base training:  33%|███▎      | 40/120 [12:27<25:10, 18.89s/it, loss=0.6642]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage1/val] epoch 040: acc_base=59.94%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage1] Supervised base training:  34%|███▍      | 41/120 [13:04<25:12, 19.14s/it, loss=0.6691]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage1/val] epoch 042: acc_base=61.75%\n",
            "[stage1] Early stopping (no improvement for 5 validations).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stage1_model = copy.deepcopy(model)"
      ],
      "metadata": {
        "id": "MTUp7LJb31fW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.2.2 Stage 2: episodic training**\n",
        "\n",
        "In the seconda phase, we freeze the **feature extractor** (to avoid forgetting base knowledge), and then we train the **few-shot weight generator** together with the base classifier weights and the learnable temperature $τ$.\n",
        "\n",
        "In each episode, some base classes are treated as *pseudo-novel*:  \n",
        "  - Their weights are excluded from the base branch through a mask.  \n",
        "  - The generator produces new weights for them using few support examples and attention over the remaining base memory.\n",
        "  \n",
        "In practice, DFSLwF does not reserve a separate novel set for Stage-2 training.  \n",
        "Splitting classes further would reduce the already limited data and break the standard evaluation protocol. Instead, pseudo-novel classes are sampled from the base set during Stage-2, while the true novel classes remain untouched until the final test.\n",
        "\n",
        "The query images are then classified against both the kept base classes and the generated novel weights.  \n"
      ],
      "metadata": {
        "id": "zYaBPBI4ssZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def evaluate_gfsl(model: DFSLwF, test_loader: DataLoader, cifar_targets_all: List[int],\n",
        "                  base_classes: List[int], device: torch.device) -> Tuple[float, float, float]:\n",
        "    model.fe.eval(); model.clf_base.eval(); model.gen.eval()\n",
        "    acc_per_episode_base, acc_per_episode_novel = [], []\n",
        "    base_order = sorted(base_classes)\n",
        "    b2local = {cid: i for i, cid in enumerate(base_order)}\n",
        "    Cb = model.clf_base.weight.size(0)\n",
        "\n",
        "    for (support_novel, query_images, true_novel_ids, gt_novel, gt_base) in test_loader:\n",
        "        support_novel = support_novel.to(device)\n",
        "        query_images = query_images.to(device)\n",
        "        gt_novel = gt_novel.to(device)\n",
        "        gt_base = gt_base.to(device)\n",
        "\n",
        "        novel_weights = model.build_novel_weights(support_novel, K_SHOT)  # (N, D)\n",
        "        logits = model.forward_logits(query_images, novel_weights)\n",
        "        preds = logits.argmax(dim=1)\n",
        "\n",
        "        N = novel_weights.size(0)\n",
        "        pred_novel = preds[:N * Q_NOVEL] - Cb\n",
        "        pred_base = preds[N * Q_NOVEL:]\n",
        "\n",
        "        id2local = {cid: i for i, cid in enumerate(true_novel_ids)}\n",
        "        gt_novel_local = torch.tensor([id2local[int(y.item())] for y in gt_novel], device=device)\n",
        "        gt_base_local = torch.tensor([b2local[int(y.item())] for y in gt_base], device=device)\n",
        "\n",
        "        acc_b = (pred_base == gt_base_local).float().mean().item()\n",
        "        acc_n = (pred_novel == gt_novel_local).float().mean().item()\n",
        "        acc_per_episode_base.append(acc_b); acc_per_episode_novel.append(acc_n)\n",
        "\n",
        "    return len(acc_per_episode_base), gfsl_stats(acc_per_episode_base, acc_per_episode_novel)"
      ],
      "metadata": {
        "id": "Q0WCFplb3CNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_logits(self, x, novel_weights=None, base_keep_mask=None):\n",
        "    feats = self.fe(x)                                  # (B, D)\n",
        "    Wb = l2_normalize(self.clf_base.weight, dim=1)      # (C_base, D)\n",
        "    if base_keep_mask is not None:\n",
        "        Wb = Wb[base_keep_mask]                         # use only base “kept”\n",
        "    logits = self.clf_base.tau * (feats @ Wb.t())\n",
        "    if novel_weights is not None and novel_weights.numel() > 0:\n",
        "        Wn = l2_normalize(novel_weights, dim=1)\n",
        "        logits = torch.cat([logits, self.clf_base.tau * (feats @ Wn.t())], dim=1)\n",
        "    return logits\n",
        "\n",
        "\n",
        "def train_stage2(model: DFSLwF, meta_loader: DataLoader, device: torch.device,\n",
        "                 base_order: List[int], n_tasks: int = STAGE2_TASKS, val_every: int = STAGE2_VAL_EVERY,\n",
        "                 lr: float = STAGE2_LR, gc: float = STAGE2_GRAD_CLIP,\n",
        "                 val_loader: Optional[DataLoader] = None):\n",
        "    \"\"\"\n",
        "    [DFSLwF] Freeze the feature extractor, train the generator and continue training W_base (and τ).\n",
        "    Exclude pseudo-novel classes both from the generator attention memory\n",
        "    and from the base branch of the classifier (using the same mask).\n",
        "    Use the true base labels for base queries; novel queries are indexed starting from Cb_kept.\n",
        "    \"\"\"\n",
        "\n",
        "    # Freeze feature extractor; keep BN statistics frozen\n",
        "    model.fe.eval(); model.fe.apply(set_bn_eval)\n",
        "    for p in model.fe.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "    # Train generator, base weights, and tau\n",
        "    for p in model.clf_base.parameters():\n",
        "        p.requires_grad = True\n",
        "    params = list(model.gen.parameters()) + [model.clf_base.tau, model.clf_base.weight]\n",
        "    opt = torch.optim.Adam(params, lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Mapping CIFAR id -> local base index [0..Cb-1]\n",
        "    b2local = {cid: i for i, cid in enumerate(sorted(base_order))}\n",
        "    Cb = model.clf_base.weight.size(0)\n",
        "\n",
        "    # Validation parameters\n",
        "    best_score = -1.0\n",
        "    patience   = 0\n",
        "    best_state = None\n",
        "\n",
        "    model.gen.train(); model.clf_base.train()\n",
        "    with tqdm(enumerate(meta_loader), total=len(meta_loader), desc=\"[Stage2] Episodic Training\") as pbar:\n",
        "        for step, (support_novel, query_images, true_novel_ids, base_q_labels_cifar) in pbar:\n",
        "            support_novel       = support_novel.to(device)\n",
        "            query_images        = query_images.to(device)\n",
        "            base_q_labels_cifar = base_q_labels_cifar.to(device)\n",
        "\n",
        "            # 1) Mask: exclude pseudo-novel classes from base (False = excluded)\n",
        "            exclude_mask = torch.ones(Cb, dtype=torch.bool, device=device)\n",
        "            for cid in true_novel_ids:\n",
        "                if cid in b2local:\n",
        "                    exclude_mask[b2local[cid]] = False\n",
        "            Cb_kept = int(exclude_mask.sum().item())\n",
        "\n",
        "            # 2) Novel weights via model helper (FE frozen inside, GEN with grad)\n",
        "            novel_weights = model.build_novel_weights(\n",
        "                support_imgs=support_novel,\n",
        "                k_shot=K_SHOT,\n",
        "                exclude_mask=exclude_mask\n",
        "            )  # (N, D)\n",
        "            N = int(novel_weights.size(0))\n",
        "\n",
        "            # 3) Logits: apply the same mask to the classifier\n",
        "            logits = model.forward_logits(\n",
        "                query_images, novel_weights, base_keep_mask=exclude_mask\n",
        "            )  # [B, Cb_kept + N]\n",
        "\n",
        "            # 4) Targets: novel after the \"kept\" base; remap base labels\n",
        "            #    Assume the first N*Q_NOVEL queries are novel, the rest are base.\n",
        "            y_novel = torch.arange(N, device=device).repeat_interleave(Q_NOVEL)  # (N*Q_NOVEL,)\n",
        "\n",
        "            # Map CIFAR base id -> local base index [0..Cb-1]\n",
        "            base_local_full = torch.tensor(\n",
        "                [b2local[int(y.item())] for y in base_q_labels_cifar],\n",
        "                device=device\n",
        "            )\n",
        "\n",
        "            # Map from [0..Cb-1] -> [0..Cb_kept-1] (=-1 if excluded)\n",
        "            keep_idx = torch.nonzero(exclude_mask, as_tuple=True)[0]\n",
        "            map_to_kept = torch.full((Cb,), -1, dtype=torch.long, device=device)\n",
        "            map_to_kept[keep_idx] = torch.arange(Cb_kept, device=device)\n",
        "            base_local_kept = map_to_kept[base_local_full]\n",
        "\n",
        "            # If the sampler produced base queries belonging to excluded (pseudo-novel) classes, fail explicitly\n",
        "            if (base_local_kept < 0).any():\n",
        "                raise ValueError(\n",
        "                    \"Stage-2: base queries contain pseudo-novel classes. \"\n",
        "                    \"Fix the sampler or filter/remap them before CE.\"\n",
        "                )\n",
        "\n",
        "            # Build targets\n",
        "            B_total = logits.size(0)\n",
        "            targets = torch.empty(B_total, dtype=torch.long, device=device)\n",
        "            # Novel occupy [Cb_kept .. Cb_kept+N-1]\n",
        "            targets[:N * Q_NOVEL] = Cb_kept + y_novel\n",
        "            # Base occupy [0 .. Cb_kept-1]\n",
        "            targets[N * Q_NOVEL:] = base_local_kept\n",
        "\n",
        "            # 5) Backpropagation\n",
        "            opt.zero_grad()\n",
        "            loss = criterion(logits, targets)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(params, gc)\n",
        "            opt.step()\n",
        "            pbar.set_postfix(loss=f\"{float(loss.item()):.4f}\")\n",
        "\n",
        "            # ---- PERIODIC VALIDATION ----\n",
        "            if val_loader is not None and ((step + 1) % val_every == 0):\n",
        "                Tval, vstats = evaluate_gfsl(model, val_loader, ds_train.targets, base_order, device)\n",
        "                v_base  = vstats[\"base\"][\"mean\"];  v_base_ci  = vstats[\"base\"][\"conf\"]\n",
        "                v_novel = vstats[\"novel\"][\"mean\"]; v_novel_ci = vstats[\"novel\"][\"conf\"]\n",
        "                v_h     = vstats[\"hmean\"][\"mean\"]; v_h_ci     = vstats[\"hmean\"][\"conf\"]\n",
        "\n",
        "                pbar.write(f\"\\t[stage2/val] step {step+1:05d}: \"\n",
        "                           f\"base={100*v_base:.2f}%±{100*v_base_ci:.2f}  \"\n",
        "                           f\"novel={100*v_novel:.2f}%±{100*v_novel_ci:.2f}  \"\n",
        "                           f\"h-mean={100*v_h:.2f}%±{100*v_h_ci:.2f}  (T={Tval})\")\n",
        "\n",
        "                sel = {\"base\": v_base, \"novel\": v_novel, \"hmean\": v_h}[S2_SELECT_METRIC]\n",
        "                if sel > best_score + 1e-6:\n",
        "                    best_score = sel\n",
        "                    patience   = 0\n",
        "                    best_state = {\n",
        "                        \"model\": copy.deepcopy(model.state_dict()),\n",
        "                        \"opt\":   copy.deepcopy(opt.state_dict()),\n",
        "                        \"step\":  step + 1,\n",
        "                        \"score\": best_score,\n",
        "                    }\n",
        "                else:\n",
        "                    patience += 1\n",
        "                    if patience >= S2_PATIENCE:\n",
        "                        pbar.write(f\"[stage2] Early stopping (no improvement for {S2_PATIENCE} validations).\")\n",
        "                        break\n",
        "\n",
        "                model.gen.train(); model.clf_base.train()\n",
        "\n",
        "    # Restore the best result\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state[\"model\"])"
      ],
      "metadata": {
        "id": "PmIOgTtNsmZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = copy.deepcopy(stage1_model)\n",
        "train_stage2(model, train_loader_s2, device=device, base_order=base_order, val_loader=val_loader_s2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffRMFtefvnma",
        "outputId": "c8df1e5e-a933-4794-b6a5-d1e32269d9f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage2] Episodic Training:   3%|▎         | 502/20000 [01:27<31:28:07,  5.81s/it, loss=0.9047]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage2/val] step 00500: base=56.23%±0.36  novel=63.45%±0.54  h-mean=59.15%±0.31  (T=1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage2] Episodic Training:   5%|▌         | 1002/20000 [02:54<33:52:32,  6.42s/it, loss=0.6350]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage2/val] step 01000: base=55.45%±0.37  novel=66.51%±0.54  h-mean=60.02%±0.31  (T=1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage2] Episodic Training:   8%|▊         | 1503/20000 [04:22<25:46:53,  5.02s/it, loss=0.6000]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage2/val] step 01500: base=55.60%±0.37  novel=66.45%±0.52  h-mean=60.09%±0.31  (T=1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage2] Episodic Training:  10%|█         | 2003/20000 [05:48<24:38:15,  4.93s/it, loss=0.6037]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage2/val] step 02000: base=55.53%±0.36  novel=67.17%±0.53  h-mean=60.34%±0.30  (T=1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage2] Episodic Training:  13%|█▎        | 2503/20000 [07:14<24:09:16,  4.97s/it, loss=0.6208]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage2/val] step 02500: base=55.06%±0.37  novel=67.08%±0.54  h-mean=60.00%±0.30  (T=1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage2] Episodic Training:  15%|█▌        | 3002/20000 [08:41<27:14:00,  5.77s/it, loss=0.5253]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage2/val] step 03000: base=55.40%±0.35  novel=67.49%±0.53  h-mean=60.42%±0.30  (T=1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage2] Episodic Training:  18%|█▊        | 3502/20000 [10:06<25:55:03,  5.66s/it, loss=0.8207]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage2/val] step 03500: base=55.36%±0.37  novel=67.44%±0.55  h-mean=60.33%±0.31  (T=1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage2] Episodic Training:  20%|██        | 4002/20000 [11:33<28:13:38,  6.35s/it, loss=0.8080]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage2/val] step 04000: base=55.83%±0.37  novel=67.69%±0.53  h-mean=60.72%±0.30  (T=1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage2] Episodic Training:  23%|██▎       | 4502/20000 [13:00<24:34:41,  5.71s/it, loss=0.7757]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage2/val] step 04500: base=55.47%±0.37  novel=67.62%±0.53  h-mean=60.49%±0.30  (T=1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage2] Episodic Training:  25%|██▌       | 5002/20000 [14:26<24:09:38,  5.80s/it, loss=0.5833]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage2/val] step 05000: base=55.66%±0.36  novel=67.37%±0.54  h-mean=60.48%±0.30  (T=1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage2] Episodic Training:  28%|██▊       | 5502/20000 [15:53<21:35:37,  5.36s/it, loss=0.6606]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage2/val] step 05500: base=55.47%±0.37  novel=68.15%±0.54  h-mean=60.69%±0.31  (T=1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage2] Episodic Training:  30%|███       | 6002/20000 [17:19<22:35:51,  5.81s/it, loss=0.5648]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage2/val] step 06000: base=55.80%±0.38  novel=67.57%±0.52  h-mean=60.67%±0.31  (T=1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage2] Episodic Training:  33%|███▎      | 6502/20000 [18:47<24:09:11,  6.44s/it, loss=0.5850]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage2/val] step 06500: base=55.86%±0.37  novel=68.20%±0.52  h-mean=60.96%±0.30  (T=1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage2] Episodic Training:  35%|███▌      | 7003/20000 [20:14<19:42:09,  5.46s/it, loss=0.6108]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage2/val] step 07000: base=56.08%±0.36  novel=68.33%±0.54  h-mean=61.15%±0.30  (T=1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage2] Episodic Training:  38%|███▊      | 7502/20000 [21:39<19:38:00,  5.66s/it, loss=0.6294]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage2/val] step 07500: base=55.70%±0.37  novel=67.94%±0.53  h-mean=60.76%±0.30  (T=1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage2] Episodic Training:  40%|████      | 8002/20000 [23:06<21:13:34,  6.37s/it, loss=0.6494]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage2/val] step 08000: base=55.93%±0.36  novel=67.63%±0.53  h-mean=60.78%±0.30  (T=1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage2] Episodic Training:  43%|████▎     | 8502/20000 [24:31<20:12:01,  6.32s/it, loss=0.5712]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage2/val] step 08500: base=56.27%±0.37  novel=67.44%±0.53  h-mean=60.93%±0.31  (T=1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage2] Episodic Training:  45%|████▌     | 9002/20000 [25:57<19:17:06,  6.31s/it, loss=0.5397]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage2/val] step 09000: base=56.12%±0.37  novel=68.67%±0.52  h-mean=61.34%±0.31  (T=1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage2] Episodic Training:  48%|████▊     | 9502/20000 [27:23<16:32:27,  5.67s/it, loss=0.6812]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage2/val] step 09500: base=56.41%±0.36  novel=68.77%±0.52  h-mean=61.58%±0.31  (T=1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage2] Episodic Training:  50%|█████     | 10003/20000 [28:50<14:05:47,  5.08s/it, loss=0.4331]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage2/val] step 10000: base=56.37%±0.37  novel=68.36%±0.52  h-mean=61.34%±0.30  (T=1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage2] Episodic Training:  53%|█████▎    | 10502/20000 [30:16<16:47:34,  6.37s/it, loss=0.5228]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage2/val] step 10500: base=55.78%±0.37  novel=68.79%±0.51  h-mean=61.18%±0.31  (T=1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage2] Episodic Training:  55%|█████▌    | 11002/20000 [31:42<15:50:29,  6.34s/it, loss=0.5635]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage2/val] step 11000: base=56.33%±0.37  novel=67.81%±0.52  h-mean=61.10%±0.31  (T=1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage2] Episodic Training:  58%|█████▊    | 11502/20000 [33:09<13:29:46,  5.72s/it, loss=0.6125]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage2/val] step 11500: base=56.57%±0.36  novel=68.39%±0.51  h-mean=61.51%±0.29  (T=1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Stage2] Episodic Training:  60%|█████▉    | 11999/20000 [34:34<23:03,  5.78it/s, loss=0.7056]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[stage2/val] step 12000: base=56.21%±0.36  novel=68.14%±0.52  h-mean=61.17%±0.30  (T=1000)\n",
            "[stage2] Early stopping (no improvement for 5 validations).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.3 Evaluation**\n",
        "\n",
        "\n",
        "After the training, we evaluate again on the **test split** with episodic testing, reporting *base accuracy*, *novel accuracy* and their **harmonic mean**, including the *confidence interval at 95%* over the test episodes.\n",
        "\n",
        "We report performance both after Stage-1 and Stage-2:\n",
        "- Stage-1 evaluation reflects the quality of the backbone and the cosine classifier trained only on base classes."
      ],
      "metadata": {
        "id": "DfsB1tdtsyKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "T, stats = evaluate_gfsl(stage1_model, test_loader, ds_test.targets, base, device=device)\n",
        "print_stats(T, stats, model=\"After stage 1 training\")"
      ],
      "metadata": {
        "id": "4saf_h3mUYfm",
        "outputId": "be9bd942-7f19-4d5b-b9ce-6b476393bad0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[test] - After stage 1 training (95% CI on 1000 tasks)\n",
            " - [Base]   acc=57.83% ± 0.36%\n",
            " - [Novel]  acc=49.35% ± 0.54%\n",
            " - [H-mean] acc=52.64% ± 0.35%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Stage-2 evaluation measures the full DFSLwF model, where the weight generator is trained to handle pseudo-novel episodes while preserving base performance.  "
      ],
      "metadata": {
        "id": "R6q9ZzcKqN3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "T, stats = evaluate_gfsl(model, test_loader, ds_test.targets, base, device=device)\n",
        "print_stats(T, stats, model=\"After stage 2 training\")"
      ],
      "metadata": {
        "id": "71N0971Mvqm6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec119d5c-243e-4f12-f8be-09b1c533b89c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[test] - After stage 2 training (95% CI on 1000 tasks)\n",
            " - [Base]   acc=57.07% ± 0.37%\n",
            " - [Novel]  acc=67.33% ± 0.56%\n",
            " - [H-mean] acc=61.30% ± 0.32%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparing the two provides evidence of how much the generator improves novel recognition without forgetting base knowledge. In fact, we can observe that:\n",
        "\n",
        "- **After Stage-1**, base accuracy is solid but novel accuracy is limited, since novel weights are only crude prototypes.  \n",
        "- **After Stage-2**, **base accuracy remains stable**, while **novel accuracy increases significantly** thanks to the generator.  \n",
        "\n",
        "As a result, the **harmonic mean rises from $≈53\\%$ to $≈61\\%$**, showing that DFSLwF successfully balances performance across base and novel classes.\n",
        "\n"
      ],
      "metadata": {
        "id": "Li2DoxThqQcq"
      }
    }
  ]
}